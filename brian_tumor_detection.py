# -*- coding: utf-8 -*-
"""Brian Tumor Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NowSvMvWmlSuhWd5X7zOlOF4L8no-2lm
"""

import warnings
warnings.filterwarnings('ignore')
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.utils import load_img, img_to_array

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib as plt
import pandas as pd
import seaborn as sns
import os
import math
import shutil
import glob

ROOT_DIR = "/content/drive/MyDrive/Brain Tumor Detection Dataset"
number_of_images = {}
for dir in os.listdir(ROOT_DIR):
    number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))

number_of_images

import os
import math
import shutil
import numpy as np

def dataFolder(p, split):
    """
    Splits data into train, validation, and test sets without deleting original images.

    Args:
        p (str): The name of the destination folder (e.g., 'train', 'val', 'test').
        split (float): The fraction of data to allocate to this folder.
    """

    if not os.path.exists("./" + p):
        os.mkdir("./" + p)

    for dir in os.listdir(ROOT_DIR):
        os.makedirs("./" + p + "/" + dir, exist_ok=True)

        # Calculate size and ensure it's not negative
        size = math.floor(split * number_of_images[dir])
        size = max(0, size)

        # Get a list of all image paths in the source directory
        source_image_paths = [os.path.join(ROOT_DIR, dir, img) for img in os.listdir(os.path.join(ROOT_DIR, dir))]

        # Randomly select image paths without replacement
        selected_image_paths = np.random.choice(source_image_paths, size=size, replace=False)

        # Copy selected images to the destination directory
        for img_path in selected_image_paths:
            destination_path = os.path.join("./" + p, dir, os.path.basename(img_path))
            shutil.copy(img_path, destination_path)  # Copy instead of move (shutil.move)

    print(f"{p} folder created (or already exists).")

dataFolder("train",0.7)

dataFolder("val",0.15)

dataFolder("test",0.15)

!pip install tensorflow

from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D

# Load pre-trained EfficientNetB0 model without the top layer
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers:
    layer.trainable = False  # Freeze base model layers initially

# Add custom classification layers
x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=output)
model.summary()

from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D

# Load pre-trained EfficientNetB0 model without the top layer
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers:
    layer.trainable = False  # Freeze base model layers initially

# Add custom classification layers
x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.5)(x)
output = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=output)
model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet import preprocess_input # Updated line

def preprocessingImages1(path):
  """
  imput : Path
  output: Pre processed images

  """
  # Use 'preprocessing_function' (singular) instead of 'preprocess_functions'
  image_data = ImageDataGenerator(zoom_range = 0.2,shear_range = 0.2,preprocessing_function = preprocess_input,horizontal_flip = True)
  image = image_data.flow_from_directory(directory = path,target_size = (224,224),batch_size = 32,class_mode = 'binary')
  return image

path = "/content/train"
train_data = preprocessingImages1(path)

train_data.class_indices

def preprocessingImages2(path):
  """
  imput : Path
  output: Pre processed images

  """
  image_data = ImageDataGenerator(preprocessing_function = preprocess_input) # Changed 'preprocessing_functions' to 'preprocessing_function'
  image = image_data.flow_from_directory(directory = path,target_size = (224,224),batch_size = 32,class_mode = 'binary')

  return image

path = "/content/test"
test_data = preprocessingImages2(path)

path = "/content/val"
val_data = preprocessingImages2(path)

import numpy as np
import matplotlib.pyplot as plt
from keras.layers import Flatten, Dense
from keras.models import Model, load_model
from tensorflow.keras.applications import MobileNet
import keras

base_model = MobileNet(input_shape = (224,224,3), include_top = False)

for layer in base_model.layers:
  layer.trainable = False

base_model.summary()

X = Flatten()(base_model.output)
X = Dense(units = 1, activation = 'sigmoid')(X)

model = Model(base_model.input, X)

model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

## Call back
from keras.callbacks import ModelCheckpoint, EarlyStopping

# model checkpoint
mc = ModelCheckpoint(filepath = "./tumormodel.keras", monitor = "val_accuracy", verbose = 1, save_best_only = True)

# Early Stopping
es = EarlyStopping(monitor = "val_accuracy", min_delta = 0.01, patience = 3, verbose = 1)

cb = [mc,es]

# puting call back in a list
call_back = [es,mc]

from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

# Callbacks for training
lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)
early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('/content/tumor_model.keras', save_best_only=True)

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30,
    callbacks=[lr_reduction, early_stopping, model_checkpoint]
)

# load the best fit model

model = load_model("/content/tumor_model.keras")

acc = model.evaluate(test_data)[1]

print(f"The accuracy of the model is {acc*100} %")

from sklearn.metrics import precision_score, recall_score, f1_score

# Ground truth labels
y_true = test_data.classes

# Predictions from the model
y_pred = model.predict(test_data)

# Convert probabilities to binary predictions (0 or 1)
y_pred_binary = (y_pred > 0.5).astype(int).flatten()

# Calculate precision, recall, and F1-score
precision = precision_score(y_true, y_pred_binary) * 100  # Convert to percentage
recall = recall_score(y_true, y_pred_binary) * 100        # Convert to percentage
f1 = f1_score(y_true, y_pred_binary) * 100               # Convert to percentage

# Print the results
print(f"Precision: {precision:.2f}%")
print(f"Recall: {recall:.2f}%")
print(f"F1-Score: {f1:.2f}%")

h = history.history # Change 'hist' to 'history'
h.keys()

plt.plot(h['accuracy'])

plt.plot(h['val_accuracy'],c="red")

plt.title("acc vs val-acc")
plt.show()

plt.plot(h['loss'])

plt.plot(h['val_loss'],c="red")

plt.title("loss vs val-loss")
plt.show()

from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.keras.preprocessing import image

import cv2  # Assuming you're using OpenCV for image loading
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.mobilenet import preprocess_input # Import from the correct location
from keras.models import load_model  # Assuming you have a pre-trained model

# Load the model (replace with your actual model file name)
# The model was saved as tumormodel.keras in the Model Training section.
model = load_model('/content/tumor_model.keras')  # Changed the file name to tumormodel.keras

# Path to your test image
path = "/content/test/yes/Te-glTr_0008.jpg"

# Load the image and resize to match model's input size
img = cv2.imread(path)  # Assuming OpenCV for image loading

# Check if image loading was successful
if img is None:
    print(f"Error: Could not load image from path: {path}")
    # Handle the error, e.g., exit the script or try a different image
else:
    img = cv2.resize(img, (224, 224))

    # Convert to a NumPy array and preprocess
    img_array = img_to_array(img)
    img_array = preprocess_input(img_array) # Now using the correct preprocess_input

    # Add batch dimension
    img_array = np.expand_dims(img_array, axis=0)

    # Make prediction
    pred = (model.predict(img_array) > 0.5).astype("int32") # Changed to get a binary prediction

    # Print prediction with class label mapping (assuming 0 is Healthy, 1 is Brain Tumor)
    if pred == 0:
        print("Healthy")
    else:
        print("Brain Tumor")

    # Display the input image for verification (optional)
    plt.imshow(img_array[0])  # Access the image from the batch dimension
    plt.show()

# Save the model to a local HDF5 file
model.save('braintumormodel.h5')

# Download the model using a method specific to your environment
# This line would depend on your environment (e.g., browser download functionality)
# I cannot provide specific guidance here without knowing your environment.
print("Your model braintumormodel.h5 is saved. Download it now!")